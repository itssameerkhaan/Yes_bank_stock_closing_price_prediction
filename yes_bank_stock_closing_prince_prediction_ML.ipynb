{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "8yEUt7NnHlrM",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "OB4l2ZhMeS1U",
        "PiV4Ypx8fxKe",
        "dJ2tPlVmpsJ0",
        "7AN1z2sKpx6M",
        "Z-hykwinpx6N",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -**`yes bank stock closing price prediction`**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual- sameer khan\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we aim to predict the closing price of Yes Bank's stock using historical financial data and machine learning techniques. The closing price of a stock is an essential indicator for investors and traders to make informed decisions regarding buying, selling, or holding the stock.\n",
        "* The primary objective of this project is to build a regression model that can accurately predict the closing price of Yes Bank's stock based on the available historical data.\n",
        "* he model will help investors and traders make more informed decisions and potentially improve their trading strategies."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/itssameerkhan/Yes_bank_stock_closing_price_prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Collection: Gather historical financial data for Yes Bank from reliable sources, such as financial websites or APIs.\n",
        "2. Data Preprocessing: Clean the data, handle missing values, and perform feature engineering to extract relevant features for the regression model.\n",
        "3. Exploratory Data Analysis (EDA): Conduct EDA to understand the distribution of the target variable (closing price) and explore relationships between features and the target variable.\n",
        "4. Feature Selection: Identify the most relevant features that have a significant impact on the closing price using correlation analysis and feature importance techniques.\n",
        "5. Model Selection: Experiment with different regression algorithms, such as Linear Regression, Decision Tree Regression, Random Forest Regression, and Gradient Boosting Regression, to determine the best-performing model.\n",
        "6. Model Training: Split the dataset into training and testing sets. Train the selected model on the training data and tune hyperparameters using cross-validation techniques to optimize model performance.\n",
        "7. Model Evaluation: Evaluate the trained model's performance on the test set using appropriate evaluation metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R2) to assess how well the model predicts the closing price.\n",
        "8. Result Interpretation: Interpret the model's predictions and provide insights into the factors influencing the closing price of Yes Bank's stock.\n",
        "Conclusion:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import plotly.graph_objects as go\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "from scipy.stats import zscore\n",
        "from tabulate import tabulate\n",
        "import scipy.stats as stats\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from statsmodels.tsa.stattools import acf,pacf\n",
        "from itertools import product\n",
        "! pip install eli5\n",
        "import eli5\n",
        "import warnings\n",
        "warnings.warn('Error: A warning just appeared')\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "! git clone https://github.com/itssameerkhan/Yes_bank_stock_closing_price_prediction.git\n",
        "data=pd.read_csv(\"/content/Yes_bank_stock_closing_price_prediction/data_YesBank_StockPrices.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f\"Number of rows  {data.shape[0]}\")\n",
        "print(f\"Number of columns {data.shape[1]}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(data.isnull())"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* total 185 rows and 5 column present in dataset.\n",
        "* And the data type of 1 column is object and remaining 4 are float type.\n",
        "* Not any null and duplicate value are present in this dataset ."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Open :- open price of that month.\n",
        "* High :- high price of that mont.\n",
        "* Low :- low at that month.\n",
        "* Close :- closing price of that month."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in data.columns.tolist():\n",
        "  print(i)\n",
        "  print(data[i].value_counts(),'\\n\\n')"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting data column string object to datetime object\n",
        "data['Date'] = data['Date'].apply(lambda x: datetime.strptime(x, \"%b-%y\"))\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set Date as index.\n",
        "data=data.set_index('Date')"
      ],
      "metadata": {
        "id": "_Yp4D0Nr98xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* convert string object to datetime object of Date column.\n",
        "* converting the Date column as index."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new copy of data for EDA.\n",
        "eda_data=data.copy()"
      ],
      "metadata": {
        "id": "AE8ERfN2ZzVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 :- **`Close price and maximum and minimum of all time of closing price`**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Candlestick(x=eda_data.index,\n",
        "                open=eda_data['Open'], high=eda_data['High'],\n",
        "                low=eda_data['Low'], close=eda_data['Close'],name='Candlestick')\n",
        "                     )\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=data.Close,marker=dict(color='red'),opacity=0.35,name='Close'))\n",
        "fig.update_layout(xaxis_rangeslider_visible=True,\n",
        "                  title_text='Close price',\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85,\n",
        "                  font=dict(family='bold',size=15))\n",
        "fig.update_yaxes(title_text='Price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "oUbilVy1O2Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data.Close,mode='markers+lines'))\n",
        "fig.add_annotation(\n",
        "        x='2018-07-01',\n",
        "        y=370,\n",
        "        xref=\"x\",\n",
        "        yref=\"y\",\n",
        "        text=\"367.9 is the maximum of all time\",\n",
        "        showarrow=True,\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=16,\n",
        "            color=\"darkslategray\"\n",
        "            ),\n",
        "        arrowhead=2,\n",
        "        arrowsize=1,\n",
        "        arrowwidth=2,\n",
        "        )\n",
        "fig.add_annotation(\n",
        "        x='2009-03-01',\n",
        "        y=11,\n",
        "        xref=\"x\",\n",
        "        yref=\"y\",\n",
        "        text=\"9.98 is the minimum of all time\",\n",
        "        showarrow=True,\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=16,\n",
        "            color=\"darkslategray\"\n",
        "            ),\n",
        "        arrowhead=8,\n",
        "        arrowsize=1,\n",
        "        ay=-70,\n",
        "        )\n",
        "fig.update_layout(title_text='Closing Price',\n",
        "                  font=dict(\n",
        "                      family=\"Courier New, monospace\",\n",
        "                      size=14,\n",
        "                      color=\"darkslategray\"),\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85\n",
        "                  )\n",
        "fig.update_yaxes(title_text='stock price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* first show the candelistic chart of close price\n",
        "* this chart show the maximum and minimum of all time of closing price."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* at 2019-07-01 the closing price 367.9 is the maximum all time .\n",
        "* at 2009-03-01 the closing price 9.98 is the minimum of all time ."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes: it helpul for understanding the closing price of stock."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2:- **`(monthly returns) monthly percentage change of closing stock price`**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use pct_change to find the percent change for each month\n",
        "eda_data['Return'] =eda_data['Close'].pct_change()\n",
        "eda_data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Bkh5SDkbDbS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "fig= go.Figure()\n",
        "fig.add_trace(go.Scatter(y=eda_data['Return'],x=eda_data.index, mode='markers+lines',line = dict(color='firebrick', width=4, dash='dot')))\n",
        "fig.update_layout(\n",
        "    title_text='monthly percentage change in Close price (yearly return)',\n",
        "    title_x=0.3,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "       family=\"Courier New, monospace\",\n",
        "       size=11,\n",
        "       color=\"darkslategray\"\n",
        "    )\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text='percentage change'\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's get an overall look at the average monthly return using a histogram.\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Histogram(x=eda_data['Return'],marker=dict(color='red')))\n",
        "fig.update_layout(\n",
        "    title_text='average monthly returen',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "        family='bold',\n",
        "        size=15\n",
        "    )\n",
        ")\n",
        "fig.update_xaxes(\n",
        "    title_text='percentage change'\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EqdNbfwbJJEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now going to analyze the risk of the stock. In order to do so we'll need to take a closer look at the yearly changes of the stock, and not just its absolute value. Let's go ahead and use pandas to retrieve the monthly returns for the stock."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* maximum fluctuation occurs in stock price is btween 2009 to 2010 and 2018 to 2020.\n",
        "* in the year of jan-2009 to may-2009 and sep-2019 to oct-2019 monthly price goes up upto 60% .\n",
        "* maximum percentage change lies between -0.2 to 0.2 ."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes:- this help us to know about yearly change in the stock.\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3:- **`all time min and max of Open stock price.`**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data.Open,mode='markers+lines'))\n",
        "fig.add_annotation(\n",
        "        x='2018-08-01',\n",
        "        y=371,\n",
        "        text=\"369.95 is the maximum of all time\",\n",
        "        showarrow=True,\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=16,\n",
        "            color=\"darkslategray\"\n",
        "            ),\n",
        "        arrowhead=2,\n",
        "        arrowsize=1,\n",
        "        arrowwidth=2,\n",
        "        )\n",
        "fig.add_annotation(\n",
        "        x='2009-03-01',\n",
        "        y=11,\n",
        "        text=\"10 is the minimum of all time\",\n",
        "        showarrow=True,\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=16,\n",
        "            color=\"darkslategray\"\n",
        "            ),\n",
        "        arrowhead=8,\n",
        "        arrowsize=1,\n",
        "        ay=-70,\n",
        "        )\n",
        "fig.update_layout(\n",
        "    title_text='stock OPEN price',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "        family='bold',\n",
        "        size=15\n",
        "    )\n",
        ")\n",
        "fig.update_yaxes(title_text='price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data.Open,line=dict(color='blue'),showlegend=False))\n",
        "fig.add_trace(go.Bar(x=eda_data.index,y=eda_data.Open ,marker=dict(color='white'),showlegend=False,textposition='auto'))\n",
        "fig.update_layout(\n",
        "    title_text='Open price',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "        family='bold',\n",
        "        size=15\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gCUBsshIb4PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "all time min and max of Open price of stock."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* all time max is 369.95 in 2018-08-01.\n",
        "* all time min is 10 in 2009-03-01."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes:- it improve the understandig of stock."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4:- **`monthly percentage change in Open price`**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "fig= go.Figure()\n",
        "fig.add_trace(go.Scatter(y=eda_data['Open'].pct_change(),x=eda_data.index, mode='markers+lines',line = dict(color='blue', width=4, dash='dot')))\n",
        "fig.update_layout(\n",
        "    title_text='monthly percentage change in Open price (montly return)',\n",
        "    title_x=0.3,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "       family=\"Courier New, monospace\",\n",
        "       size=11,\n",
        "       color=\"darkslategray\"\n",
        "    )\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text='percentage change'\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's get an overall look at the average monthly return using a histogram.\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Histogram(x=eda_data['Open'].pct_change(),marker=dict(color='blue')))\n",
        "fig.update_layout(\n",
        "    title_text='Open monthly percentage change',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "        family='bold',\n",
        "        size=15\n",
        "    )\n",
        ")\n",
        "fig.update_xaxes(\n",
        "    title_text='percentage change'\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "WuYEMHcjQzLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "monthly percentage change in Open price"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Apr-2009 to jul-2009 and oct-2019 to jan-2019 in this months the percentage change in Open price goes more than 60%.\n",
        "* oct-2008 to jan-2009, sep-20018 to nov-2018 andjul-2020 to aug-2020 in this monts the percentage change is lowest in Open price , goes in negative 40%.\n",
        "* the maximum percentage chage lies between 10 to 20 %."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":yes:"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5:- **`yearly changes in Close price.`**"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "color=['green',]*13+['red']*3\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=eda_data.resample('Y').mean().index,\n",
        "                     y=eda_data.resample('Y').mean()['Close'],showlegend=False,marker=dict(color=color),name='Close'))\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=eda_data.resample('Y').mean().index,\n",
        "    y=eda_data.resample('Y').mean()['Close'],\n",
        "    text=round(eda_data.resample('Y').mean()['Close'],3),\n",
        "    mode='text',\n",
        "    textposition='top center',\n",
        "    textfont=dict(\n",
        "        size=14,\n",
        "    ),\n",
        "    showlegend=False\n",
        "))\n",
        "fig.add_trace(go.Scatter(x=eda_data.resample('Y').mean().index,y=eda_data.resample('Y').mean()['Close']*1.2,mode='lines',name='trend',showlegend=False))\n",
        "fig.update_layout(title_text='Yearly changes in Close price',\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85,\n",
        "                  font=dict(\n",
        "                      family='bold',\n",
        "                      size=15\n",
        "                  ))\n",
        "fig.update_yaxes(title_text='Price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yearly changes in close price and show the trend in stock price ."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in between 2006 to 2018 the trend is upword and sudden 2019 to 2021 the closing price of stock goes down."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it show the stock is going down after 2019."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6:- **`yearly returns of stock`** ."
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "color=[]\n",
        "for i in eda_data.resample('Y').mean()['Return']:\n",
        "  if i < 0:\n",
        "    color.append('red')\n",
        "  else:\n",
        "    color.append('green')\n",
        "\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.resample('Y').mean().index,\n",
        "                         y=eda_data.resample('Y').mean()['Return']*0.2,line=dict(color='#d9967e'),showlegend=False,name='yearly return'))\n",
        "fig.add_trace(go.Bar(x=eda_data.resample('Y').mean().index,\n",
        "                     y=eda_data.resample('Y').mean()['Return'],marker=dict(color=color),showlegend=False,name='yearly return'))\n",
        "fig.update_layout(\n",
        "    title_text=\"Yearly returns of stock price\",\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "        family='bold',\n",
        "        size=15\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this shows, yearly return of stock price"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* stock price goes down in 2019,2012,2014,2016,2019,2020,2021 and in 2019 to 2021 stock price goes down rapidaly .\n",
        "* all green bar show stock price moving upword and 2018 this year the sock goes upword rapidaly"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see the every year increament and dicreament in stock price."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7:- **`All time high price of stock .`**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data.High,mode='markers+lines'))\n",
        "fig.add_annotation(\n",
        "    text='All time high price :- 404',\n",
        "    x='2018-08-01',\n",
        "    y=408,\n",
        "    arrowhead=4,\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=13\n",
        "    )\n",
        ")\n",
        "fig.update_layout(\n",
        "    title_text='All time high price',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "        size=15,\n",
        "        family='bold'\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "txIFoYa_8v7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "showing all time high price of stock."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All time high price is 404."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8:- **`All time Low price of stock.`**"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Low'],mode='lines+markers',line=dict(color='red')))\n",
        "fig.add_annotation(\n",
        "    text='All time Low = 5.55',\n",
        "    x='2020-03-01',\n",
        "    y=6,\n",
        "    arrowhead=3,\n",
        "    arrowsize=2,\n",
        "    ay=-90,\n",
        "    ax=30\n",
        ")\n",
        "fig.update_layout(\n",
        "    title_text='All time Low price ',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    font=dict(\n",
        "        family='bold',\n",
        "        size=15\n",
        "    )\n",
        ")\n",
        "fig.update_yaxes(title_text='price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "zhE57w_RmFQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All time low price of stock ."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "all time low price is 5.55"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes: it help to uderstand the stock"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9:- **`simple moving average (SMV)`**"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'],name='closing price'))\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'].rolling(window=5,min_periods=1).mean(),name='window 5'))\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'].rolling(window=10,min_periods=1).mean(),name='window 10'))\n",
        "fig.update_layout(title_text='simple moving average [Close price]',\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85,\n",
        "                  font=dict(family='bold',\n",
        "                            size=15))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple moving average"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Trend**: By looking at the blue line (closing price), you can observe the overall trend of the financial instrument. If the line is consistently going upwards, it indicates an uptrend, while a consistent downward movement suggests a downtrend.\n",
        "* **Moving Averages**: The orange line represents the 5-day simple moving average, and the green line represents the 10-day simple moving average. When the closing price (blue line) is above the moving averages, it suggests a positive trend, and vice versa.\n",
        "* **Volatility**: The distance between the blue line and the moving averages can provide insights into the volatility of the financial instrument. When the lines are close together, it indicates relatively low volatility, while wider gaps suggest higher volatility."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this show the Trend and moving average and volatility of stock."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 :- **`Cumulative moving average (cmv)`**"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'].expanding().mean(),name='CMV'))\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'],name='closing price'))\n",
        "fig.update_layout(title_text='cumulative moving average',\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85,\n",
        "                  font=dict(family='bold',size=15))\n",
        "fig.update_yaxes(title_text='price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cumulative moving average"
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The blue line represents the cumulative moving average (CMA) of the closing price\n",
        "* **Trend**: By examining the blue CMA line, you can get a sense of the long-term trend in the closing price of the financial instrument. If the CMA is consistently rising over time, it indicates a general upward trend in the price.\n",
        "* **Price Movements**: The orange line represents the actual closing price of the financial instrument. By comparing the blue line to the orange CMA line, you can identify periods when the closing price is above or below the CMA. When the closing price is above the CMA, it suggests that the price is performing better than the long-term average, and vice versa."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it indicates a general upward trend in the price"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 :- **`Exponential moving average (EMA)`**"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'],name='closing price'))\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'].ewm(alpha=0.1,adjust=False).mean(),name='alpha=0.1'))\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'].ewm(alpha=0.5,adjust=False).mean(),name='alpha=0.5'))\n",
        "fig.update_layout(title_text='Exponential moving average (EMA)',\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85,\n",
        "                  font=dict(family='bold',\n",
        "                            size=15))\n",
        "fig.update_yaxes(title_text='price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exponential moving average (EMA)"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Closing Price Trend: The first line represents the closing prices of the financial asset over time. By observing this line, we can see the general trend of the asset's price movement. If the line is mostly ascending, it indicates a positive price trend\n",
        "* Alpha = 0.1 : The second line represents the Exponential Moving Average (EMA) of the closing prices with a smoothing factor (alpha) of 0.1.it may provide earlier signals for potential price reversals or short-term trends.\n",
        "* Alpha = 0.5 EMA: The third line represents another EMA of the closing prices, but this time with a larger smoothing factor of 0.5.It is more useful for identifying longer-term trends or significant price movements.\n",
        "* Comparing EMAs: When the EMA lines cross each other or the closing price line, it might signal a shift in the trend direction.\n",
        "* Volatility: The distance between the closing price line and the EMAs indicates the volatility of the asset's price. If the closing price line is more distant from the EMAs, it indicates higher volatility, and if it's closer, it suggests lower volatility."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it helps to understand the trend and volatility of stock price."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 :- **`Exponential moving weighted average (EMWA)`**"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'],name='closing price'))\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'].ewm(span=4,adjust=False).mean(),name='span=4'))\n",
        "fig.add_trace(go.Scatter(x=eda_data.index,y=eda_data['Close'].ewm(span=2,adjust=False).mean(),name='span=2'))\n",
        "fig.update_layout(title_text='Exponential moving weigheted average (EMWA)',\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85,\n",
        "                  font=dict(family='bold',\n",
        "                            size=15))\n",
        "fig.update_yaxes(title_text='Price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exponential moving weighted average :- this is use to find the smothness and trend of the stock."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* EMWA with Span=4: The second line represents the Exponential Moving weighted Average of the closing prices with a span of 4 periods. The EMA with a span of 4 means it's giving more weight to the most recent four data points.\n",
        "* EMWA with Span=2: The third line represents another EMWA of the closing prices, but this time with a smaller span of 2 periods. The EMA with a span of 2 gives even more weight to the most recent two data points, making it highly responsive to immediate price changes.\n",
        "* Comparing EMAs: By comparing the closing price line to the EMAs with spans of 4 and 2, traders and analysts can identify potential short-term and very short-term trends.When the closing price line diverges significantly from the EMAs with spans of 4 and 2, it may indicate potential overbought or oversold conditions in the market. Divergence occurs when the price and the EMA lines move in opposite directions, suggesting a possible upcoming reversal in the short-term trend."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes:-"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13:- **`Seasonal Decomposition of Time Series (STL)`**"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = sm.tsa.seasonal_decompose(data['Close'], model='additive', period=10)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(result.trend)\n",
        "plt.title('Trend')\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(result.seasonal)\n",
        "plt.title('Seasonal')\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(result.resid)\n",
        "plt.title('Residual')\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(data['Close'])\n",
        "plt.title('Original Data')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this show the seasonality, trend and residual of time series."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Befor 2018 the trend is increasind and after 2018 the trend is dicreasing.\n",
        "\n",
        "* The seasonal component represents the repeating patterns or periodic fluctuations in the data. These are yearly patterns. Identifying and understanding seasonal patterns can be valuable for various applications, such as demand forecasting.\n",
        "\n",
        "* The residual, in 2018 to 2020 there is highest noisy deta are avilable ."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this help us to understand the trend and smothness in data which help us in treding ."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - **`Correlation Heatmap`**"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "correlation_matrix=eda_data.drop(columns=['Return'],axis=1).corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this show the correlation in variables"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every feature is extremely corelated with each other, so taking just one feature or average of these features would suffice for our regression model as linear regression assumes there is no multi colinearity in the features."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - **`Pair Plot`**"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(eda_data.drop(columns=['Return']))"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this show the relationship of varainale with each other."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the variables of this dataset is **` linearly related`** to each other."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dickey-fuller test- for stationarity test.\n",
        "* pearnson correlation test - for correlation test.\n",
        "* Testing the Significance of Individual Coefficients- for knowing the strength of independent variable to dependent variable.\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1 :- **`Dickey-fuller Test`**"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  if pvalue <= 0.05 --Reject the null hypothesis. The time series is stationary.\n",
        "*  if pvalue > 0.05 --Fail to reject the null hypothesis. The time series is non-stationary."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "result = sm.tsa.adfuller(data['Close'])\n",
        "print(\"ADF Statistic:\", result[0])\n",
        "print(\"p-value:\", result[1])\n",
        "print(\"Critical Values:\")\n",
        "for key, value in result[4].items():\n",
        "    print(f\"\\t{key}: {value}\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if result[1] <= 0.05:\n",
        "    print(\"Reject the null hypothesis. The time series is stationary.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The time series is non-stationary.\")"
      ],
      "metadata": {
        "id": "Q8rhcUirCgXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dickey-fuller test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stationary test of time series data."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2 :- **`pearnson correlation test`**"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  if pvalue <= 0.05 --Reject the null hypothesis. The columns is not highly correlated.\n",
        "*  if pvalue > 0.05 --Fail to reject the null hypothesis. The columns is highly correlated."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "for i in data.columns.tolist():\n",
        "  for j in data.columns.tolist():\n",
        "     correlation_coefficient, p_value = stats.pearsonr(data[i], data[j])\n",
        "     print(\"           \",i,\" : \",j,\"           \")\n",
        "     print(\"Pearson correlation coefficient:\", correlation_coefficient)\n",
        "     print(\"p-value:\", p_value,\"\\n\")"
      ],
      "metadata": {
        "id": "cfs9OUpVY3O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pearnson correlation test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this show the correlation of each column to each others."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3:- **`Testing the Significance of Individual Coefficients`**"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Null Hypothesis (H0): The coefficient of the predictor variable is equal to zero (there is no relationship between the predictor and the response).\n",
        "* Alternative Hypothesis (H1): The coefficient of the predictor variable is not equal to zero (there is a statistically significant relationship between the predictor and the response)."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "X=data.drop(columns=['Close'])\n",
        "Y=data.Close\n",
        "# Add a constant to the predictor variables for the intercept term\n",
        "X = sm.add_constant(X)\n",
        "stats_model = sm.OLS(Y, X)\n",
        "results =stats_model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=results.pvalues.index\n",
        "value=results.pvalues.values\n",
        "for column,p_value in zip(index,value):\n",
        "  if p_value<0.05:\n",
        "    print(f\"{column}: variable is statistically significant in explaining the variation in the target variable\")\n",
        "  else:\n",
        "    print(f\"{column}: variable is statistically NOT significant in explaining the variation in the target variable\")"
      ],
      "metadata": {
        "id": "NGehFFm-JLc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Significance of Individual Coefficients."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first hypothesis test evaluates the significance of each individual coefficient (slope) in the regression model. Each coefficient represents the change in the response variable associated with a one-unit change in the corresponding predictor variable, assuming all other predictors are held constant."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see , there is not any missing value present in the dataset."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seasonal_decomposition(ts):\n",
        "    decomposition = STL(ts, seasonal=13)\n",
        "    result = decomposition.fit()\n",
        "    return result.trend, result.seasonal, result.resid\n",
        "trend, seasonal, residual = seasonal_decomposition(data['Close'])\n",
        "def detect_anomalies(residual, threshold=3.5):\n",
        "    z_scores = np.abs(zscore(residual))\n",
        "    anomalies = np.where(z_scores > threshold)[0]\n",
        "    return anomalies,z_scores\n",
        "\n",
        "anomalies,z_score = detect_anomalies(residual)\n",
        "sns.histplot(z_score)\n",
        "plt.title('z_score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "red_mu=residual.mean()\n",
        "red_dev=residual.std()\n",
        "uper_lim=red_mu+(3*red_dev)\n",
        "lower_lim=red_mu-(3*red_dev)"
      ],
      "metadata": {
        "id": "hDHTsxKgkkll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_sea=trend+seasonal\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=data.index,y=data['Close'],name='close price'))\n",
        "fig.add_trace(go.Scatter(x=res_sea.index,y=res_sea.values,name='trend+seasonality'))\n",
        "fig.add_trace(go.Scatter(x=data.index[anomalies],y=data['Close'][anomalies],mode='markers',name='annomalies',marker=dict(color='red')))\n",
        "fig.add_trace(go.Scatter(x=data.index,y=z_score,name='z_score'))\n",
        "fig.update_layout(title_text='Annomalies in close price',\n",
        "                  title_x=0.5,\n",
        "                  title_y=0.85,\n",
        "                  font=dict(family='bold',\n",
        "                            size=15))\n",
        "res_sea=trend+seasonal\n",
        "fig2=go.Figure()\n",
        "fig2.add_hline(y=uper_lim)\n",
        "fig2.add_hline(y=lower_lim)\n",
        "fig2.add_trace(go.Scatter(y=residual,x=data.index,marker=dict(color='red')))\n",
        "fig2.update_yaxes(title_text='residuals')\n",
        "fig2.update_layout(shapes=[\n",
        "    dict(type='rect',\n",
        "         xref='paper',\n",
        "         yref='y',\n",
        "         x0=0,\n",
        "         y0=lower_lim,\n",
        "         x1=1,\n",
        "         y1=uper_lim,\n",
        "         fillcolor='green',\n",
        "         opacity=0.2,\n",
        "         line=dict(width=0),\n",
        "    )\n",
        "])\n",
        "fig2.show()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FAZsfoh5NzmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use the Seasonal-Trend decomposition using LOESS (STL) to decompose the time series into its trend, seasonal, and residual components. Then, we use the Grubbs test (z-score) to identify anomalies in the residual component."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "data.info()"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "not any categorical variable is present in dataset."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# here we are going to prepeare dataset for time series forcasting .\n",
        "data_time=data[['Close']].copy()\n",
        "#note by hypothesis test 1(dickey fuller test) we can find that the 'Close' feature is not stationary so we are going to convert dataset to stationary data.\n",
        "data_time['Close_log_diff']=np.log(data_time['Close'])-np.log(data_time['Close']).shift(1)\n",
        "#now i am going to cheak stationary again.\n",
        "result = sm.tsa.adfuller(data_time['Close_log_diff'].dropna())\n",
        "if result[1] <= 0.05:\n",
        "    print(f\"p_value is :- {result[1]}\")\n",
        "    print(\"Reject the null hypothesis. The time series is stationary.\")\n",
        "else:\n",
        "    print(f\"p_value is :- {result[1]}\")\n",
        "    print(\"Fail to reject the null hypothesis. The time series is non-stationary.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=data_time.index,y=data_time['Close_log_diff'],name='log_diff'))\n",
        "fig.add_trace(go.Scatter(x=data_time.index,y=data_time['Close_log_diff'].rolling(12).mean(),name='rolling mean'))\n",
        "fig.add_trace(go.Scatter(x=data_time.index,y=data_time['Close_log_diff'].rolling(12).std(),name='rolling std'))\n",
        "fig.update_layout(title_text='STATIONARY CLOSE VALUES',font=dict(family='bold',size=15),title_x=0.5,title_y=0.85)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Bm23Ir6JMVQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now here we can see no any divergen (upword and downword patter in mean and std) so this seres is stationary now."
      ],
      "metadata": {
        "id": "dH1rUBTMOx3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.drop(columns='Close')\n",
        "y=data.Close"
      ],
      "metadata": {
        "id": "mEGNql16HbVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are doing f_regression method for feature selection\n",
        "from sklearn.feature_selection import f_regression\n",
        "f_r=f_regression(X, y, center=True, force_finite=True)\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=X.columns,y=f_r[0],marker=dict(color=['red','yellow','green'])))\n",
        "fig.update_layout(title_text='f_regression technique',\n",
        "                  title_x=0.5,title_y=0.85,\n",
        "                  font=dict(family='bold',size=15))\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "s05IfTaxQ-Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are cheacking the variances in  each variable in independent variable.\n",
        "feature_variances = X.var()\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=feature_variances.index,y=feature_variances.values))\n",
        "fig.update_layout(title_text='variances in independent variable',\n",
        "                  title_x=0.5,title_y=0.85,\n",
        "                  font=dict(family='bold',size=15))\n",
        "fig.update_xaxes(title_text='features name')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fd6C7zVQU_-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. f_regression method.\n",
        "2. variance threshold method."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* from f_regression method 'LOW' feature is very important for regression model.\n",
        "* and from variances all feature are having same amount of variance in their region.\n",
        "\n",
        "by doing feature selection, i can understand this the LOW column in very important but i m not going to drop other feature because **`in this dataset there is not any problem of overfiting`** ."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here we can see the distribution of values in variable by QQ plot and dist plot.\n",
        "for col in data.columns:\n",
        "  plt.figure(figsize=(14,4))\n",
        "  plt.subplot(121)\n",
        "  sns.histplot(data[col], bins=20, kde=True)\n",
        "  plt.title(col)\n",
        "\n",
        "  plt.subplot(122)\n",
        "  stats.probplot(data[col],dist='norm',plot=plt)\n",
        "  plt.title(col)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "gTw4qvZlc62w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here all the variable of dataset is not linearly distributed all are moltidomialy distributed. So we are going to make it in linear distribution ."
      ],
      "metadata": {
        "id": "VTKssr-niyvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we are going to do transformation for convert all variable into linearly distributed variable.\n",
        "#A power transform will make the probability distribution of a variable more Gaussian.\n",
        "pt=PowerTransformer()\n",
        "transform_data=pt.fit_transform(data)\n",
        "transform_data=pd.DataFrame(transform_data,columns=data.columns)"
      ],
      "metadata": {
        "id": "wxFnFuo5iyDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in transform_data.columns:\n",
        "  plt.figure(figsize=(14,4))\n",
        "  plt.subplot(121)\n",
        "  sns.histplot(transform_data[col], bins=20, kde=True)\n",
        "  plt.title(col)\n",
        "\n",
        "  plt.subplot(122)\n",
        "  stats.probplot(transform_data[col],dist='norm',plot=plt)\n",
        "  plt.title(col)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "H1A9P7SE-SFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now detaset is converted almost in linear distribution."
      ],
      "metadata": {
        "id": "0KPqG0Mh-qWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "table=[['column_name','skewness'],\n",
        "       ['Opne',transform_data['Open'].skew()],\n",
        "       ['High',transform_data['High'].skew()],\n",
        "       ['Low',transform_data['Low'].skew()],\n",
        "       ['Close',transform_data['Close'].skew()]]\n",
        "print(tabulate(table,headers='firstrow',tablefmt='grid'))"
      ],
      "metadata": {
        "id": "YqmORutlDFxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we dont need to scale this dataset because the skewness of this datset is alredy removed by transformation."
      ],
      "metadata": {
        "id": "6mO-uGjqFLP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " When dealing with datasets that have a large number of features or variables, dimensionality reduction can help simplify the data and make it more manageable for analysis and modeling.\n",
        "\n",
        " but in this dataset feature is very less so we could not use dimesionality reduction."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "#we are not going to do any dimesionality reduction"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we are going to train the model on two type of data .\n",
        "1. original data\n",
        "2. transform data"
      ],
      "metadata": {
        "id": "VCl3KTWOov3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# spliting the origina data\n",
        "x_train=data.drop(columns=['Close'])[:110]\n",
        "x_test=data.drop(columns=['Close'])[110:]\n",
        "y_train=data['Close'][:110]\n",
        "y_test=data['Close'][110:]\n",
        "# splitig the transform data\n",
        "transform_x_train=transform_data.drop(columns=['Close'])[:110]\n",
        "transform_x_test=transform_data.drop(columns=['Close'])[110:]\n",
        "transform_y_train=transform_data['Close'][:110]\n",
        "transform_y_test=transform_data['Close'][110:]"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting ratio of train test is 110:75"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NO becouse it is a regression problem and there is not any imblalanced variable are present ."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1:- **`ElasticNet`**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`note`**:- here i am going to do model implementation on both.\n",
        "1. Oringina data.\n",
        "2. transformed data."
      ],
      "metadata": {
        "id": "UyIrSxrxRC4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "model=ElasticNet()\n",
        "t_model=ElasticNet()\n",
        "# Fit the Algorithm\n",
        "model.fit(x_train,y_train)\n",
        "t_model.fit(transform_x_train,transform_y_train)\n",
        "# Predict on the model\n",
        "y_pred=model.predict(x_test)\n",
        "t_y_pred=t_model.predict(transform_x_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "r2=r2_score(y_pred,y_test)\n",
        "t_r2=r2_score(t_y_pred,transform_y_test)\n",
        "cv=np.mean(cross_val_score(model,x_train,y_train,scoring='r2'))\n",
        "t_cv=np.mean(cross_val_score(t_model,transform_x_train,transform_y_train,scoring='r2'))\n",
        "table=[['','r2 score','mean(cross_score)'],\n",
        "       ['without transformetion',r2,cv],\n",
        "       ['with transformetion',t_r2,t_cv]]\n",
        "print(tabulate(table,headers='firstrow',tablefmt='grid'))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating function for Visualizing evaluation Metric Score chart\n",
        "\n",
        "#creating a fuction for visualize the original and predicted value\n",
        "def pred_org(y_test,y_pred,text):\n",
        "  mse = np.mean((y_test - y_pred) ** 2)\n",
        "  mae = np.mean(np.abs(y_test - y_pred))\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = (1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2)))*100\n",
        "  fig=go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=[min(y_test), max(y_test)],y=[min(y_test), max(y_test)],name='Ideal_line'))\n",
        "  fig.add_trace(go.Scatter(x=y_test,y=y_pred,mode='markers',name='prediction'))\n",
        "  fig.update_xaxes(title_text='original value')\n",
        "  fig.update_yaxes(title_text='predicted value')\n",
        "  if text=='original':\n",
        "    fig.update_layout(title_text='EVALUATION MATRICS OF ORIGINAL DATA',\n",
        "                      title_x=0.5,title_y=0.85,\n",
        "                      font=dict(color='blue',size=15,family='bold'))\n",
        "  else:\n",
        "    fig.update_layout(title_text='EVALUATION MATRICS OF TRANSFORM DATA',\n",
        "                      title_x=0.5,title_y=0.85,\n",
        "                      font=dict(color='blue',size=15,family='bold'))\n",
        "  fig.show()\n",
        "\n",
        "#this fuction is for error and evulation matics.\n",
        "def error_score(y_test,y_pred):\n",
        "  mse = np.mean((y_test - y_pred) ** 2)\n",
        "  mae = np.mean(np.abs(y_test - y_pred))\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = (1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2)))*100\n",
        "  header=['','score']\n",
        "  values=[\n",
        "       ['Mean Squared Error (MSE)',mse],\n",
        "       ['Root Mean Squared Error (RMSE)',rmse],\n",
        "       ['Mean Absolute Error (MAE)',mae],\n",
        "       ['R-squared (R2)',r2]]\n",
        "  evaluation_metrics = ['Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)', 'Mean Absolute Error (MAE)', 'R-squared (R2)']\n",
        "  metric_scores = [mse, rmse, mae, r2]\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 3), sharex=True)\n",
        "  axes[0].table(cellText=values, colLabels=header, cellLoc='center', loc='center')\n",
        "  axes[0].set_xticklabels([])\n",
        "  axes[0].set_yticklabels([])\n",
        "  axes[1].bar(evaluation_metrics, metric_scores,  color='blue')\n",
        "  axes[1].set_xlabel('')\n",
        "  axes[1].set_ylabel('score')\n",
        "  axes[1].tick_params(axis='x', rotation=90)\n",
        "  axes[1].grid(True)\n",
        "  axes[1].set_xticklabels([])\n",
        "  for i,j in zip(evaluation_metrics,metric_scores):\n",
        "    axes[1].text(i,j+2,i.split(' ')[-1])\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "#comparison between transfrom and original scores\n",
        "def com_score(y_test,y_pred,t_y_test,t_y_pred):\n",
        "  mse = np.mean((y_test - y_pred) ** 2)\n",
        "  mae = np.mean(np.abs(y_test - y_pred))\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = (1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2)))*100\n",
        "\n",
        "  t_mse = np.mean((t_y_test - t_y_pred) ** 2)\n",
        "  t_mae = np.mean(np.abs(t_y_test - t_y_pred))\n",
        "  t_rmse = np.sqrt(t_mse)\n",
        "  t_r2 = (1 - (np.sum((t_y_test - t_y_pred) ** 2) / np.sum((t_y_test - np.mean(t_y_test)) ** 2)))*100\n",
        "  table=[['','r2 score','mean(cv_score)','Mean Squared Error (MSE)','Root Mean Squared Error (RMSE)','Mean Absolute Error (MAE)'],\n",
        "        ['without transformetion',r2,cv,mse,rmse,mae],\n",
        "        ['with transformetion',t_r2,t_cv,t_mse,t_rmse,t_mae]]\n",
        "  print('                                   METRIC SCORE CHART TRAMFORMED AMD ORIGINAL DATA ')\n",
        "  print(tabulate(table,headers='firstrow',tablefmt='grid'))\n",
        "\n",
        "#with or without hypermeter tunning comparison\n",
        "def com_tunning_model(y_test,y_pred,t_y_pred):\n",
        "  t_y_test=y_test\n",
        "  mse = np.mean((y_test - y_pred) ** 2)\n",
        "  mae = np.mean(np.abs(y_test - y_pred))\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = (1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2)))*100\n",
        "\n",
        "  t_mse = np.mean((t_y_test - t_y_pred) ** 2)\n",
        "  t_mae = np.mean(np.abs(t_y_test - t_y_pred))\n",
        "  t_rmse = np.sqrt(t_mse)\n",
        "  t_r2 = (1 - (np.sum((t_y_test - t_y_pred) ** 2) / np.sum((t_y_test - np.mean(t_y_test)) ** 2)))*100\n",
        "  table=[['','r2 score','Mean Squared Error (MSE)','Root Mean Squared Error (RMSE)','Mean Absolute Error (MAE)'],\n",
        "        ['without tunning',r2,mse,rmse,mae],\n",
        "        ['with tunnig',t_r2,t_mse,t_rmse,t_mae]]\n",
        "  print('                                   METRIC SCORE CHART TUNNING AMD WITHOUT TUNNIG MODEL ')\n",
        "  print(tabulate(table,headers='firstrow',tablefmt='grid'))"
      ],
      "metadata": {
        "id": "MsB1Br6a57W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ecaluation matrics and score chart on original data\n",
        "pred_org(y_test,y_pred,'original')\n",
        "error_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "UlNg14gRF8v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ecaluation matrics and score chart on Transform data\n",
        "pred_org(transform_y_test,t_y_pred,'transform')\n",
        "error_score(transform_y_test,t_y_pred)"
      ],
      "metadata": {
        "id": "S4oZd3139wMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparison between transformed and original data\n",
        "com_score(y_test,y_pred,transform_y_test,t_y_pred)"
      ],
      "metadata": {
        "id": "EN7mJBP0QLET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`note:-`** i am going to do Hyperparameter tunning on transformed data."
      ],
      "metadata": {
        "id": "YZ3cbZgyvzaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid = {\n",
        "    'max_iter': [1, 5, 10,15],\n",
        "    'alpha': [0.1, 1.0, 10.0],\n",
        "    'l1_ratio': [0.1, 0.5, 0.9]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=t_model, param_grid=param_grid, cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_search.fit(transform_x_train, transform_y_train)\n",
        "print(grid_search.best_params_)\n",
        "# Predict on the model\n",
        "t2_model=ElasticNet(alpha=grid_search.best_params_['alpha'],l1_ratio=grid_search.best_params_['l1_ratio'],max_iter=grid_search.best_params_['max_iter'])\n",
        "t2_model.fit(transform_x_train, transform_y_train)\n",
        "t2_y_pred=t2_model.predict(transform_x_test)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we can see the original and prediction values after hyperperameter tinning the model\n",
        "pred_org(transform_y_test,t2_y_pred,'transform')"
      ],
      "metadata": {
        "id": "8BZLZXkDvWKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid search Cv"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_tunning_model(transform_y_test,t_y_pred,t2_y_pred)"
      ],
      "metadata": {
        "id": "1ym2TRd9xOf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we clearly see the improvment in the model performence.\n",
        "1. r2 score goes from -169 to 96.\n",
        "2. mean squared error goes from 2.47 to 0.03.\n",
        "3. root mean square error goes from 1.572 to 0.174.\n",
        "4. mean absolute error goes from 1.456 to 0.137."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 :- **`LassoCV`**"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`note`**:- here i am going to do model implementation on both.\n",
        "1. Oringina data.\n",
        "2. transformed data."
      ],
      "metadata": {
        "id": "Isx1ZY0M_aIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "from sklearn.linear_model import LassoCV\n",
        "l_model=LassoCV()\n",
        "t_l_model=LassoCV()\n",
        "# Fit the Algorithm\n",
        "t_l_model.fit(transform_x_train,transform_y_train)\n",
        "l_model.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "t_l_pred=t_l_model.predict(transform_x_test)\n",
        "l_pred=l_model.predict(x_test)"
      ],
      "metadata": {
        "id": "jGfQpbwO3Cj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "l_r2=r2_score(l_pred,y_test)\n",
        "t_l_r2=r2_score(t_l_pred,transform_y_test)\n",
        "l_cv=np.mean(cross_val_score(model,x_train,y_train,scoring='r2'))\n",
        "t_l_cv=np.mean(cross_val_score(t_l_model,transform_x_train,transform_y_train,scoring='r2',cv=10))\n",
        "table=[['','r2 score','mean(cross_score)'],\n",
        "       ['without transformetion',l_r2,l_cv],\n",
        "       ['with transformetion',t_l_r2,t_l_cv]]\n",
        "print(tabulate(table,headers='firstrow',tablefmt='grid'))"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we can see the evaluation metrics and prediction on original data.\n",
        "pred_org(y_test,l_pred,'original')\n",
        "error_score(y_test,l_pred)"
      ],
      "metadata": {
        "id": "-MGWEo5o6f-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we can see the evaluation metrics and prediction on transform data.\n",
        "pred_org(transform_y_test,t_l_pred,'transform')\n",
        "error_score(transform_y_test,t_l_pred)"
      ],
      "metadata": {
        "id": "KA0HoXMG6fUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "alphas =[0.01, 0.1, 1.0, 10.0]\n",
        "lasso_cv = LassoCV(alphas=alphas, cv=5)\n",
        "# Fit the Algorithm\n",
        "lasso_cv.fit(transform_x_train, transform_y_train)\n",
        "best_alpha = lasso_cv.alpha_\n",
        "# Predict on the model\n",
        "lasso_pred=lasso_cv.predict(transform_x_test)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LassoCV automates this process by performing cross-validation to find the best alpha value that provides the best trade-off between model complexity and performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not any improvements occurs after tunning the model."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_tunning_model(transform_y_test,t_l_pred,lasso_pred)"
      ],
      "metadata": {
        "id": "t-RVlvvu9dXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we clearly see the improvment in the model performence.\n",
        "1. r2 score goes from 99.11 to 98.67.\n",
        "2. mean squared error goes from 0.008 to 0.012.\n",
        "3. root mean square error goes from 0.089 to 0.110.\n",
        "4. mean absolute error goes from 0.058 to 0.0781."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 :- **`SARIMAX`**"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our data is not stationary it is seasonal. We need to use the Seasonal ARIMA (SARIMA) model for Time Series Forecasting on this data. But before using the SARIMA model, we will use the ARIMA model. It will help you learn using both models."
      ],
      "metadata": {
        "id": "simEXpnqjqrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [acf,pacf]:\n",
        "  if i == acf:\n",
        "    text='AUTO CORRELATION'\n",
        "  else:\n",
        "    text='PARTIAL AUTO COERELATION'\n",
        "  fig=go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=[str(i) for i in range(21)],y=i(data_time['Close_log_diff'].dropna(),nlags=20),mode='markers+lines'))\n",
        "  fig.update_layout(shapes=[\n",
        "    dict(\n",
        "         x0=-1,\n",
        "         y0=-1.96/np.sqrt(len(data_time['Close_log_diff'])),\n",
        "         x1=21,\n",
        "         y1=1.96/np.sqrt(len(data_time['Close_log_diff'])),\n",
        "         fillcolor='red',\n",
        "         opacity=0.3,\n",
        "        )\n",
        "        ],\n",
        "                    height=450,\n",
        "                    title_text=text,\n",
        "                    title_x=0.5,title_y=0.85,font=dict(\n",
        "                        family='bold',\n",
        "                        size=15\n",
        "                    ))\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "-t32UTQtL7N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* p=7\n",
        "* d=1\n",
        "* q=7"
      ],
      "metadata": {
        "id": "orIMYb1Oj1Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "model=sm.tsa.statespace.SARIMAX(data_time['Close'][:185],\n",
        "                                order=(7, 1, 7),\n",
        "                                seasonal_order=(7, 1, 7, 12))\n",
        "# Fit the Algorithm\n",
        "model=model.fit()\n",
        "# Predict on the model\n",
        "predictions = model.predict(160, 190)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=data_time.index,y=data_time['Close'],name='origina'))\n",
        "fig.add_trace(go.Scatter(x=data_time.index[160:],y=predictions,name='predicted'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "M9z6h13JkJPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"                            Akaike's Information Criterion (AIC) of this model is :- \",model.aic)\n",
        "error_score(y_test=data_time['Close'][160:],y_pred=predictions)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter ranges to search over.\n",
        "p_range = range(0, 8)\n",
        "d_range = range(0, 2)\n",
        "q_range = range(0, 8)\n",
        "P_range = range(0, 2)\n",
        "D_range = range(0, 2)\n",
        "Q_range = range(0, 2)\n",
        "s_range = [12]\n",
        "hyperparameter_combinations = list(product(p_range, d_range, q_range, P_range, D_range, Q_range, s_range))\n",
        "\n",
        "best_aic = float(\"inf\")\n",
        "best_params = None\n",
        "\n",
        "# Loop through all combinations and fit SARIMAX models\n",
        "for params in hyperparameter_combinations:\n",
        "    try:\n",
        "        model = sm.tsa.SARIMAX(data_time['Close'], order=params[:3], seasonal_order=params[3:], enforce_stationarity=False, enforce_invertibility=False)\n",
        "        results = model.fit()\n",
        "\n",
        "        # Choose a performance metric (AIC in this case) to evaluate models\n",
        "        aic = results.aic\n",
        "\n",
        "        # Update best model if the current model has a lower AIC\n",
        "        if aic < best_aic:\n",
        "            best_aic = aic\n",
        "            best_params = params\n",
        "\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# Re-fit the best model with the selected hyperparameters\n",
        "best_model = sm.tsa.SARIMAX(data_time['Close'], order=best_params[:3], seasonal_order=best_params[3:], enforce_stationarity=False, enforce_invertibility=False)\n",
        "best_results = best_model.fit()\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best AIC:\", best_aic)\n",
        "print(\"Best Model Summary:\")\n",
        "print(best_results.summary())\n"
      ],
      "metadata": {
        "id": "vLjRg5oEo1ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is a simpel itretion of p,d,q value from a range of p,d,q."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error (MSE): The MSE is one of the most widely used metrics for regression problems. It calculates the average of the squared differences between predicted and actual values. The lower the MSE, the better the model performance."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i am going to choose the **LassoCV**  simple linear regression model for this detaset. And this show the best performace from all other models ."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate feature importances using permutation importance\n",
        "# The 'model' argument can be your trained LassoCV model\n",
        "perm_importance = eli5.sklearn.PermutationImportance(l_model, random_state=42)\n",
        "perm_importance.fit(x_train, y_train)\n",
        "\n",
        "# Display feature importances\n",
        "eli5.show_weights(perm_importance, feature_names=X.columns.tolist())"
      ],
      "metadata": {
        "id": "iV2J81DOi5Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eli5.show_prediction(l_model , np.array(x_test)[1],feature_names=data.drop(columns=['Close']).columns.tolist(),show_feature_values=True)"
      ],
      "metadata": {
        "id": "TkEUJcwuDmF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from the above two tables how LassoCV assigned weights for each feature based on training data and from the other table, for a particular instance, to reach a probability of prediction for row 1 how each feature has contributed.   "
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Not a single null vlaue was present in this detaset.\n",
        "* And not even any outlliers are present.\n",
        "* eventhough each features are heighly correlated to each other but i did not drop any column becouse there is already features are very less.\n",
        "* All variable is statistically signigicant in explaining the variation in target variable.\n",
        "* There is three outliers i found but i cant droped them bcause it not afecting the variance and next reason is there is less amount of input are present.\n",
        "* i transform the data with power transformer which make the probability distribution of a variable.\n",
        "* i implement two regression model 1. ElsticNET 2. LassoCV and third model is a time series forecasting model which is SERIMAX ( seasonal auto-regressive integrated moving average with exagenous factores ).\n",
        "* And LassoCV is the main model from all the models which i impremented because\n",
        "         1. ElasticNet  original form MSE is 151.25, and transform MSE is 0.0304.\n",
        "         2. LassoCV  original form MSE is 150, and transform MSE is 0.0122.\n",
        "         3. SARIMAX  origina form MSE is 517 .\n",
        "* High and Low this feature are taking heigh contribution in prediction and in other hand Low feature is contributing very less .\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}